{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55e8e1a-9592-4cf4-955d-c7f1cfa49b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the hashtag to search for (include #):  #chennai\n",
      "Enter the maximum number of tweets to extract:  400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets saved to chennai_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "# options.add_argument(\"--headless\")  # Enable headless mode for faster scraping\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "driver_path = r\"C:\\Users\\New\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(service=Service(driver_path), options=options)\n",
    "\n",
    "# Navigate to Twitter login page\n",
    "driver.get(\"https://twitter.com/login\")\n",
    "time.sleep(30)  # Wait for manual login\n",
    "\n",
    "# Input hashtag and max tweets\n",
    "hashtag = input(\"Enter the hashtag to search for (include #): \").strip()\n",
    "max_tweets = int(input(\"Enter the maximum number of tweets to extract: \"))\n",
    "\n",
    "# Navigate to Twitter's search page\n",
    "url = f\"https://twitter.com/search?q={hashtag}&src=typed_query&f=live\"\n",
    "driver.get(url)\n",
    "time.sleep(10)  # Allow initial tweets to load\n",
    "\n",
    "# Scrape tweets\n",
    "tweets_data = []\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while len(tweets_data) < max_tweets:\n",
    "    tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]')\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        try:\n",
    "            content = tweet.find_element(By.XPATH, './/div[@lang]').text\n",
    "        except:\n",
    "            content = None\n",
    "        try:\n",
    "            username = tweet.find_element(By.XPATH, './/span[contains(text(), \"@\")]').text\n",
    "        except:\n",
    "            username = None\n",
    "        try:\n",
    "            date = tweet.find_element(By.XPATH, './/time').get_attribute(\"datetime\")\n",
    "        except:\n",
    "            date = None\n",
    "        try:\n",
    "            retweets = tweet.find_element(By.XPATH, './/button[@data-testid=\"retweet\"]/div[@dir=\"ltr\"]/div/span/span').text\n",
    "        except:\n",
    "            retweets = \"0\"\n",
    "        try:\n",
    "            comments = tweet.find_element(By.XPATH, './/button[@data-testid=\"reply\"]/div[@dir=\"ltr\"]/div/span/span').text \n",
    "\n",
    "        except:\n",
    "            comments = \"0\"\n",
    "        try:\n",
    "            likes = tweet.find_element(By.XPATH, './/button[@data-testid=\"like\"]/div[@dir=\"ltr\"]/div/span/span').text\n",
    "        except:\n",
    "            likes = \"0\"\n",
    "\n",
    "        try:\n",
    "            views = tweet.find_element(By.XPATH, './/a[contains(@href, \"/analytics\")]').get_attribute(\"aria-label\")\n",
    "        except:\n",
    "            views = \"0 Views\"\n",
    "        try:\n",
    "            images = tweet.find_elements(By.XPATH, './/img[contains(@src, \"twimg\")]')\n",
    "            image_urls = [img.get_attribute(\"src\") for img in images]\n",
    "        except:\n",
    "            image_urls = []\n",
    "        try:\n",
    "            hashtags = [tag.text for tag in tweet.find_elements(By.XPATH, './/a[contains(@href, \"/hashtag/\")]')]\n",
    "        except:\n",
    "            hashtags = []\n",
    "        try:\n",
    "            is_verified = bool(tweet.find_element(By.XPATH, './/svg[@aria-label=\"Verified account\"]'))\n",
    "        except:\n",
    "            is_verified = False\n",
    "\n",
    "        tweet_data = {\n",
    "            \"user_posted\": username,\n",
    "            \"date_posted\": date,\n",
    "            \"description\": content,\n",
    "            \"views\": views,\n",
    "            \"replies\": comments,\n",
    "            \"reposts\": retweets,\n",
    "            \"likes\": likes,\n",
    "            \"hashtags\": \", \".join(hashtags),\n",
    "            \"is_verified\": is_verified,\n",
    "            \"photos\": \", \".join(image_urls),\n",
    "            \"url\": url\n",
    "        }\n",
    "\n",
    "        if tweet_data not in tweets_data:\n",
    "            tweets_data.append(tweet_data)\n",
    "        if len(tweets_data) >= max_tweets:\n",
    "            break\n",
    "\n",
    "    # Scroll down\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(10)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height:  # End scrolling if no new content\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Save tweets to CSV\n",
    "if tweets_data:\n",
    "    output_file = f\"{hashtag[1:]}_tweets.csv\"\n",
    "    df = pd.DataFrame(tweets_data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Tweets saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No tweets found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
